# Awesome-Agent-Training
[![PR Welcome](https://img.shields.io/badge/PRs-welcome-brightgreen)](https://github.com/bruno686/Awesome-Agent-Training/pulls)
[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](LICENSE)
[![Awesome](https://awesome.re/badge.svg)](https://awesome.re)

We are witnessing an exciting era where LLM capabilities have rapidly advanced in just a few years, enabling lower costs and stronger performance for real-world applications.

The next key step is to enhance Language Agents' ability to handle diverse tasks, which is crucial for deployment. We also focus on optimizing their structure and training methods to improve task completion rates.

Training Language Agents is an essential yet still emerging technology. This repository is dedicated to pushing the boundaries and exploring new possibilities in this field.

<!-- * [] []() () 
* [] []() () () -->

## Papers

### Fine-tuning Paradigm
* [2310] [FireAct: Toward Language Agent Fine-tuning](https://arxiv.org/abs/2310.05915) (Princeton)

### Reinforment Learning Paradigm
* [2503] [SWEET-RL: Training Multi-Turn LLM Agents on Collaborative Reasoning Tasks](https://arxiv.org/pdf/2503.15478) (Meta, UC Berkeley)
* [2502] [Digi-Q: Learning Q-Value Functions for Training Device-Control Agents](https://arxiv.org/pdf/2502.15760) (UC Berkeley, UIUC, Amazon, CMU)
* [2412] [Proposer-Agent-Evaluator(PAE): Autonomous Skill Discovery For Foundation Model Internet Agents](https://arxiv.org/pdf/2412.13194) (UC Berkeley, UIUC, Amazon)
* [2406] [DigiRL: Training In-The-Wild Device-Control Agents with Autonomous Reinforcement Learning](https://arxiv.org/pdf/2406.11896) (UC Berkeley, UIUC, Google DeepMind)
* [2402] [ArCHer: Training Language Model Agents via Hierarchical Multi-Turn RL](https://arxiv.org/pdf/2402.19446) (UC Berkeley, Google DeepMind)

### Non-training Agent (Architecture Desining)
* [2309] [You Only Look at Screens: Multimodal Chain-of-Action Agents](https://arxiv.org/pdf/2309.11436) (SJTU, Meta)
* [2312] [CogAgent: A Visual Language Model for GUI Agents](https://arxiv.org/pdf/2312.08914) (THU, Zhipu AI)


## Open-Source Project
* ![RAGEN Stars](https://img.shields.io/github/stars/RAGEN-AI/RAGEN) [RAGEN](https://github.com/RAGEN-AI/RAGEN) (Training agent)
* ![RAGEN Stars](https://img.shields.io/github/stars/PeterGriffinJin/Search-R1) [Search-R1](https://github.com/PeterGriffinJin/Search-R1) (Train your LLMs to reason and call a search engine with reinforcement learning)
* ![OpenManus-RL Stars](https://img.shields.io/github/stars/OpenManus/OpenManus-RL) [OpenManus-RL](https://github.com/OpenManus/OpenManus-RL) (A live stream development of RL tunning for LLM agents)
* ![MetaSpatial Stars](https://img.shields.io/github/stars/PzySeere/MetaSpatial) [MetaSpatial](https://github.com/PzySeere/MetaSpatial) (Reinforcing 3D Spatial Reasoning in VLMs for the Metaverse)

## Contributing

* Feel free to contribute more papers or other any resources!
