# Awesome-Agent-Training
[![PR Welcome](https://img.shields.io/badge/PRs-welcome-brightgreen)](https://github.com/bruno686/Awesome-Agent-Training/pulls)
[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](LICENSE)
[![Awesome](https://awesome.re/badge.svg)](https://awesome.re)

We are witnessing an exciting era where LLM capabilities have rapidly advanced in just a few years, enabling lower costs and stronger performance for real-world applications.

The next key step is to enhance Language Agents' ability to handle diverse tasks, which is crucial for deployment. We also focus on optimizing their structure and training methods to improve task completion rates.

Training Language Agents is an essential yet still emerging technology. This repository is dedicated to pushing the boundaries and exploring new possibilities in this field.

[The Second Half](https://ysymyth.github.io/The-Second-Half/)


<!-- * [] []() () 
* [] []() () () -->

## Papers

### Fine-tuning Paradigm
* [2503] [PLAN-AND-ACT: Improving Planning of Agents for Long-Horizon Tasks](https://arxiv.org/pdf/2503.09572) (UCB)
* [2503] [MPO:BoostingLLMAgentswithMetaPlanOptimization](https://arxiv.org/pdf/2503.02682) (PKU)
* [2503] [ATLaS: Agent Tuning via Learning Critical Steps](https://arxiv.org/pdf/2503.02197) (UTS, UMD)
* [2501] [Agent-R: Training Language Model Agents to Reflect via Iterative Self-Training](https://arxiv.org/pdf/2501.11425) (ByteDance)
* [2310] [FireAct: Toward Language Agent Fine-tuning](https://arxiv.org/abs/2310.05915) (Princeton)

### Reinforment Learning Paradigm
* [2504] [LLMs are Greedy Agents: Effects of RL Fine-tuning on Decision-Making Abilities](https://arxiv.org/pdf/2504.16078) (Google DeepMind)
* [2504] [Meta-Thinking in LLMs via Multi-Agent Reinforcement Learning: A Survey](https://arxiv.org/pdf/2504.14520)
* [2504] [OTC: Optimal Tool Calls via Reinforcement Learning](https://arxiv.org/pdf/2504.14870) (CUHK, UIUC)
* [2504] [ReTool: Reinforcement Learning for Strategic Tool Use in LLMs](https://arxiv.org/pdf/2504.11536) (ByteDance)
* [2504] [Synthetic Data Generation & Multi-Step RL for Reasoning & Tool Use](https://arxiv.org/pdf/2504.04736) (Stanford University, Google DeepMind)
* [2504] [DeepResearcher: Scaling Deep Research via Reinforcement Learning in Real-world Environments](https://arxiv.org/pdf/2504.03160) (SJTU)
* [2503] [Rec-R1: Bridging Generative Large Language Models and User-Centric Recommendation Systems via Reinforcement Learning](https://arxiv.org/pdf/2503.24289) (UIUC, Amazon)
* [2503] [ReSearch: Learning to Reason with Search for LLMs via Reinforcement Learning](https://arxiv.org/pdf/2503.19470) (Baichuan)
* [2503] [R1-Searcher: Incentivizing the Search Capability in LLMs via Reinforcement Learning](https://arxiv.org/pdf/2503.05592) (RUC)
* [2503] [UI-R1: Enhancing Action Prediction of GUI Agents by Reinforcement Learning](https://arxiv.org/pdf/2503.21620) (Vivo Lab, CUHK)
* [2503] [Thinking Longer, Not Larger: Enhancing Software Engineering Agents via Scaling Test-Time Compute](https://arxiv.org/pdf/2503.23803) (Tongyi Lab) 
* [2503] [Search-R1: Training LLMs to Reason and Leverage Search Engines with Reinforcement Learning](https://arxiv.org/pdf/2503.09516?) (UIUC)
* [2503] [SWEET-RL: Training Multi-Turn LLM Agents on Collaborative Reasoning Tasks](https://arxiv.org/pdf/2503.15478) (Meta, UC Berkeley)
* [2503] [ReMA: Learning to Meta-think for LLMs with Multi-Agent Reinforcement Learning](https://arxiv.org/pdf/2503.09501) (SJTU)
* [2502] [Digi-Q: Learning Q-Value Functions for Training Device-Control Agents](https://arxiv.org/pdf/2502.15760) (UC Berkeley, UIUC, Amazon, CMU)
* [2502] [STeCa: Step-level Trajectory Calibration for LLM Agent Learning](https://arxiv.org/pdf/2502.14276) (PolyU)
* [2502] [EPO: Explicit Policy Optimization for Strategic Reasoning in LLMs via Reinforcement Learning](https://arxiv.org/pdf/2502.12486) (UCAS)
* [2502] [Reinforcement Learning for Long-Horizon Interactive LLM Agents](https://arxiv.org/pdf/2502.01600) (Apple)
* [2502] [Training a Generally Curious Agent](https://arxiv.org/pdf/2502.17543) (CMU)
* [2501] [Improving Vision-Language-Action Model with Online Reinforcement Learning](https://arxiv.org/pdf/2501.16664) (THU)
* [2412] [Proposer-Agent-Evaluator(PAE): Autonomous Skill Discovery For Foundation Model Internet Agents](https://arxiv.org/pdf/2412.13194) (UC Berkeley, UIUC, Amazon)
* [2406] [DigiRL: Training In-The-Wild Device-Control Agents with Autonomous Reinforcement Learning](https://arxiv.org/pdf/2406.11896) (UC Berkeley, UIUC, Google DeepMind)
* [2402] [ArCHer: Training Language Model Agents via Hierarchical Multi-Turn RL](https://arxiv.org/pdf/2402.19446) (UC Berkeley, Google DeepMind)

### Non-training Agent (Architecture Desining)
* [2309] [You Only Look at Screens: Multimodal Chain-of-Action Agents](https://arxiv.org/pdf/2309.11436) (SJTU, Meta)
* [2312] [CogAgent: A Visual Language Model for GUI Agents](https://arxiv.org/pdf/2312.08914) (THU, Zhipu AI)


## Open-Source Project
* ![RAGEN Stars](https://img.shields.io/github/stars/RAGEN-AI/RAGEN) [RAGEN](https://github.com/RAGEN-AI/RAGEN) (Training agent)
* ![RAGEN Stars](https://img.shields.io/github/stars/PeterGriffinJin/Search-R1) [Search-R1](https://github.com/PeterGriffinJin/Search-R1) (Train your LLMs to reason and call a search engine with reinforcement learning)
* ![OpenManus-RL Stars](https://img.shields.io/github/stars/OpenManus/OpenManus-RL) [OpenManus-RL](https://github.com/OpenManus/OpenManus-RL) (A live stream development of RL tunning for LLM agents)
* ![MetaSpatial Stars](https://img.shields.io/github/stars/PzySeere/MetaSpatial) [MetaSpatial](https://github.com/PzySeere/MetaSpatial) (Reinforcing 3D Spatial Reasoning in VLMs for the Metaverse)

## Contributing

* Feel free to contribute more papers or other any resources!
